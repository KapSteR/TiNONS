\section*{Discussion}
This section contains a brief discussion of the results of the five different classification methods which have been used throughout this project. The resulting accuracy is shown on table \ref{table:result}.

\begin{table}[h]
\begin{tabular}{@{}l|lll@{}}
\toprule
Model 		   		   & One digit            & Two digits  & Ten digits   \\ \midrule
ANN                    & 95.3 \%                & 93.1 \%   & 89.4 \% \\
GMM                    & 94.6 \%                & 91.2 \%   & 89.1 \% \\
SVM                    & 73.7 \%                & - 	    & -       \\ 
PGM                    & 62.7 \% 				& 58.1 \%   & 57.2 \% \\
Linear                 & 55.9 \% 				& 51.2 \%   & 50.6 \%

\end{tabular}
\caption{The table shows the overall accuracy of classification for the model used in this project. }
\label{table:result}
\end{table}

In this project the speaker base only contain three people and are therefore fairly limited. 
Some of the models that was used to classify the data may not work with different speakers or a large group of speakers.
To make the models more robust are large base of speakers is needed.
For some of the models three speakers base is already at the limited of the computer power and time available.\\

A way to make the models more robust is the usage of a universal background model.
The UBM is described in \cite{Springer:36}.\\

The lowest classification accuracy is found in the linear models, which was expected because of the simplicity of the model.
The dataset has a lot of dimensions and overlapping, and therefore too complex for a linear decision boundary.
The second lowest classification accuracy is found in the probabilistic generative model. 
The PGM is also too simple a model to handle the dataset, but still more complex than the linear model, which is expressed in the accuracy.
One of the problems with PGM is that numbers of independent variable that have to be determined for each class scale with the number of dimensions.\\

The middle accuracy model is the support vector machine.
The training phase needs to be iterated a large number of times, and therefore takes a considerable time to do. 
The result of the smallest dataset isn't that accurate so it was not worth applying the model on the other two datasets.\\

The model with the second highest classification accuracy is the Gaussian mixture model.
The model have a overall accuracy close to ANN, and are working well as a classifier for speaker recognition. 
The reason for the good result can be that the GMM have more than one Gaussian to describe each class.
The training phase of GMM was computational load heavy, but the classification didn't demand so much.\\

The model that have the highest classification accuracy of speaker recognition is the artificial neural network.
The model was found to be very demanding regarding the computational load during the training phase. 
This is because the ANN doesn't have a single minimum, and therefore the training needs to be iterated a large number of times. 




