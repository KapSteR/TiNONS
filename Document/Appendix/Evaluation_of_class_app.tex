\chapter{Evaluation of classification methods}
The individual classification methods are evaluated with datasets of varying complexities.
Most notably, with speakers uttering the same single digit ("\textit{ZERO}"), two different digits ("\textit{ZERO}" and "\textit{ONE}"), and ten different digits ("\textit{ZERO}", "\textit{ONE}" through "\textit{NINE}").


To evaluate a classifier, the confusion matrix is an ideal way of doing so.
The confusion matrix can show the classifications sensitivity, precision and accuracy for each class. 
The terms used to describe this is: false positive (\textit{FP}), true positive (\textit{TP}), false negative (\textit{FN}) and true negative (\textit{TN}).
The true terms are classes that are correctly classified and false terms are incorrectly classified.
The sensitivity is the probability of classifying the inputs as class $X$ for a input that are class $X$.
\begin{equation}
\mathtt{sensitivity}(X) = \dfrac{TP_X}{TP_X+\Sigma FN_X}
\label{eq:sensitivity}
\end{equation}
The precision is the probability that the estimate of class $X$ is correct.
\begin{equation}
\mathtt{precision}(X) = \dfrac{TP_X}{TP_X+\Sigma FP_X}
\label{eq:precision}
\end{equation}
The accuracy is the probability that the classification of any given class is correct, where N = total number of tests.
\begin{equation}
\mathtt{accuray}(X) = \dfrac{\Sigma TP_X}{\mathrm{N}}
\label{eq:accuracy}
\end{equation}

\begin{table}[H]                                              
\centering                                                     
\begin{tabular}{|l|c|c|c|c|}                                   
\hline                                                         
  & Speaker Jacob & Speaker Mose & Speaker Simon & Precision [\%] \\
\hline                                                         
Estimate Jacob & 6300.0 & 0.0 & 0.0 & 100.0 \\                 
\hline                                                         
Estimate Mose & 10.0 & 5790.0 & 100.0 & 98.1 \\                
\hline                                                         
Estimate Simon & 600.0 & 1120.0 & 6810.0 & 79.8 \\             
\hline                                                         
Sensitivity [\%] & 91.2 & 83.8 & 98.6 & 91.2 \\                
\hline                                                         
\end{tabular}                                                  
\caption{Example of confusion matrix. GMM classification with 3 speakers and 2 digits spoken}                          
\label{table:Ex_conf}                                       
\end{table}

Above in Table \ref{table:Ex_conf} an example of a confusion matrix in shown.
The far right column shows the precision as calculated with (\ref{eq:precision}), 
the bottom row shows the sensitivity as calculated with (\ref{eq:sensitivity})
and the bottom right field shows the overall accuracy as calculated with (\ref{eq:accuracy}).
This is the way, along with some plots of target vs. estimate, that the results of using various methods for classification will be presented in this project.

The evaluation of classifiers will primarily be based on overall accuracy of the classifier. 

